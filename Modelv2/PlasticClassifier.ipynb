{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db58a838-5d33-4756-870d-eb97d6f4fe51",
   "metadata": {},
   "source": [
    "# Classifying patches\n",
    "\n",
    "Training a CNN to classify patches of plastic waste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be6d7c-6c68-4683-857d-e8813685a5c5",
   "metadata": {},
   "source": [
    "- Diving the dataset\n",
    "- Creating a dataloader\n",
    "- Performing transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7466099-293c-4d71-aabf-2e763757aff2",
   "metadata": {},
   "source": [
    "## Divinding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f0cb91-4d9b-4787-9cd0-aeef3d655fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7827c-8eb8-447a-bad0-4225cc08be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563a7e6e-153e-43b4-b886-a4f5a8a17148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\"./dataset2/\", transform=Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f369af93-54fb-4258-b6cd-60010048b402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33714"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15987e6-4cc6-43ff-beef-963f07882eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=.20)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "15e483a2-73d9-4160-81de-64975666e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump([train_idx, val_idx, test_idx], open(\"data.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a404a6da-d32c-407c-99f1-d958511043b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(dataset, train_idx)\n",
    "val_data = Subset(dataset, val_idx)\n",
    "test_data = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda5492f-a1f3-46e0-9043-e95c2cd336b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_data, BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117367c3-563e-471f-b0d7-13e90ce65a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(i[0].shape, i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef059a1e-e9c1-41f1-a000-95ef4f6d4bdb",
   "metadata": {},
   "source": [
    "## CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1283c6e7-8d86-42ac-988e-b01c58bfbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dfd33b3-9cdd-4bd5-931d-6bcb3f1bd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlasticClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlasticClassifier, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, 3, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(8*6*6, 128),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.linear_layers(out)\n",
    "        return out\n",
    "    \n",
    "model = PlasticClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "933410a5-0dce-4bc3-9d01-11598f7a1e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 128.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*6*6, 256/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a36f098-265d-4f90-bffa-58775e88c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(model(i[0]).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5deee019-0f70-4d8d-9d44-c8b729c4edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(),\n",
    "                           lr=0.05)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88e0fef0-0dee-4574-a798-de0b6eb12079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging the training\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bf8d1a5-a4a8-4fed-ae1d-7a1dab8c590f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0\n",
      "----------\n",
      "\tLoss: 0.694176, Images:0.00%\n",
      "\tLoss: 0.689962, Images:25.08%\n",
      "\tLoss: 0.693932, Images:50.16%\n",
      "\tLoss: 0.692694, Images:75.24%\n",
      "Epoch:     0, loss: 138.5995498895645, acc: 0.511912\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "----------\n",
      "\tLoss: 0.689462, Images:0.00%\n",
      "\tLoss: 0.686250, Images:25.08%\n",
      "\tLoss: 0.689572, Images:50.16%\n",
      "\tLoss: 0.690980, Images:75.24%\n",
      "Epoch:     1, loss: 138.28362107276917, acc: 0.525235\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "----------\n",
      "\tLoss: 0.682947, Images:0.00%\n",
      "\tLoss: 0.634799, Images:25.08%\n",
      "\tLoss: 0.534720, Images:50.16%\n",
      "\tLoss: 0.493589, Images:75.24%\n",
      "Epoch:     2, loss: 120.74755993485451, acc: 0.677900\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "----------\n",
      "\tLoss: 0.457336, Images:0.00%\n",
      "\tLoss: 0.550659, Images:25.08%\n",
      "\tLoss: 0.424312, Images:50.16%\n",
      "\tLoss: 0.440128, Images:75.24%\n",
      "Epoch:     3, loss: 101.6241996884346, acc: 0.763323\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "----------\n",
      "\tLoss: 0.426599, Images:0.00%\n",
      "\tLoss: 0.581118, Images:25.08%\n",
      "\tLoss: 0.515029, Images:50.16%\n",
      "\tLoss: 0.413820, Images:75.24%\n",
      "Epoch:     4, loss: 97.57088965177536, acc: 0.784796\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "----------\n",
      "\tLoss: 0.511669, Images:0.00%\n",
      "\tLoss: 0.371834, Images:25.08%\n",
      "\tLoss: 0.443041, Images:50.16%\n",
      "\tLoss: 0.397146, Images:75.24%\n",
      "Epoch:     5, loss: 93.58074600994587, acc: 0.795925\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "----------\n",
      "\tLoss: 0.537843, Images:0.00%\n",
      "\tLoss: 0.398526, Images:25.08%\n",
      "\tLoss: 0.457728, Images:50.16%\n",
      "\tLoss: 0.339110, Images:75.24%\n",
      "Epoch:     6, loss: 91.03159368038177, acc: 0.799530\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "----------\n",
      "\tLoss: 0.447229, Images:0.00%\n",
      "\tLoss: 0.479287, Images:25.08%\n",
      "\tLoss: 0.397622, Images:50.16%\n",
      "\tLoss: 0.426355, Images:75.24%\n",
      "Epoch:     7, loss: 89.74507275223732, acc: 0.806426\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "----------\n",
      "\tLoss: 0.439123, Images:0.00%\n",
      "\tLoss: 0.591014, Images:25.08%\n",
      "\tLoss: 0.296547, Images:50.16%\n",
      "\tLoss: 0.360264, Images:75.24%\n",
      "Epoch:     8, loss: 87.0438566505909, acc: 0.814420\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "----------\n",
      "\tLoss: 0.448853, Images:0.00%\n",
      "\tLoss: 0.385642, Images:25.08%\n",
      "\tLoss: 0.473036, Images:50.16%\n",
      "\tLoss: 0.223367, Images:75.24%\n",
      "Epoch:     9, loss: 86.38918009400368, acc: 0.819122\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "----------\n",
      "\tLoss: 0.390771, Images:0.00%\n",
      "\tLoss: 0.526244, Images:25.08%\n",
      "\tLoss: 0.320912, Images:50.16%\n",
      "\tLoss: 0.432061, Images:75.24%\n",
      "Epoch:    10, loss: 84.50024248659611, acc: 0.813480\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "----------\n",
      "\tLoss: 0.402708, Images:0.00%\n",
      "\tLoss: 0.463520, Images:25.08%\n",
      "\tLoss: 0.476194, Images:50.16%\n",
      "\tLoss: 0.328503, Images:75.24%\n",
      "Epoch:    11, loss: 83.4048394113779, acc: 0.823041\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "----------\n",
      "\tLoss: 0.267355, Images:0.00%\n",
      "\tLoss: 0.400839, Images:25.08%\n",
      "\tLoss: 0.388983, Images:50.16%\n",
      "\tLoss: 0.271535, Images:75.24%\n",
      "Epoch:    12, loss: 82.22127050161362, acc: 0.817868\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "----------\n",
      "\tLoss: 0.474924, Images:0.00%\n",
      "\tLoss: 0.253062, Images:25.08%\n",
      "\tLoss: 0.434904, Images:50.16%\n",
      "\tLoss: 0.576586, Images:75.24%\n",
      "Epoch:    13, loss: 82.26216323673725, acc: 0.826332\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "----------\n",
      "\tLoss: 0.498723, Images:0.00%\n",
      "\tLoss: 0.382341, Images:25.08%\n",
      "\tLoss: 0.510537, Images:50.16%\n",
      "\tLoss: 0.243457, Images:75.24%\n",
      "Epoch:    14, loss: 79.84207601845264, acc: 0.830878\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "----------\n",
      "\tLoss: 0.509589, Images:0.00%\n",
      "\tLoss: 0.385084, Images:25.08%\n",
      "\tLoss: 0.421058, Images:50.16%\n",
      "\tLoss: 0.341921, Images:75.24%\n",
      "Epoch:    15, loss: 80.60715617239475, acc: 0.828840\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "----------\n",
      "\tLoss: 0.375729, Images:0.00%\n",
      "\tLoss: 0.250334, Images:25.08%\n",
      "\tLoss: 0.342713, Images:50.16%\n",
      "\tLoss: 0.327316, Images:75.24%\n",
      "Epoch:    16, loss: 78.76061263680458, acc: 0.837774\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "----------\n",
      "\tLoss: 0.224573, Images:0.00%\n",
      "\tLoss: 0.346731, Images:25.08%\n",
      "\tLoss: 0.228701, Images:50.16%\n",
      "\tLoss: 0.328181, Images:75.24%\n",
      "Epoch:    17, loss: 78.1559199243784, acc: 0.837774\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "----------\n",
      "\tLoss: 0.166060, Images:0.00%\n",
      "\tLoss: 0.405227, Images:25.08%\n",
      "\tLoss: 0.559799, Images:50.16%\n",
      "\tLoss: 0.508528, Images:75.24%\n",
      "Epoch:    18, loss: 78.03269191086292, acc: 0.834169\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "----------\n",
      "\tLoss: 0.321170, Images:0.00%\n",
      "\tLoss: 0.330880, Images:25.08%\n",
      "\tLoss: 0.405898, Images:50.16%\n",
      "\tLoss: 0.472510, Images:75.24%\n",
      "Epoch:    19, loss: 75.45180524885654, acc: 0.846082\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "----------\n",
      "\tLoss: 0.328508, Images:0.00%\n",
      "\tLoss: 0.272703, Images:25.08%\n",
      "\tLoss: 0.405441, Images:50.16%\n",
      "\tLoss: 0.231740, Images:75.24%\n",
      "Epoch:    20, loss: 75.14461416006088, acc: 0.847806\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "----------\n",
      "\tLoss: 0.278937, Images:0.00%\n",
      "\tLoss: 0.616494, Images:25.08%\n",
      "\tLoss: 0.400721, Images:50.16%\n",
      "\tLoss: 0.342874, Images:75.24%\n",
      "Epoch:    21, loss: 74.68614700436592, acc: 0.847022\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "----------\n",
      "\tLoss: 0.425440, Images:0.00%\n",
      "\tLoss: 0.322468, Images:25.08%\n",
      "\tLoss: 0.253434, Images:50.16%\n",
      "\tLoss: 0.260794, Images:75.24%\n",
      "Epoch:    22, loss: 73.36254805326462, acc: 0.852038\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "----------\n",
      "\tLoss: 0.331000, Images:0.00%\n",
      "\tLoss: 0.367233, Images:25.08%\n",
      "\tLoss: 0.417699, Images:50.16%\n",
      "\tLoss: 0.286351, Images:75.24%\n",
      "Epoch:    23, loss: 73.21544468402863, acc: 0.850157\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "----------\n",
      "\tLoss: 0.428803, Images:0.00%\n",
      "\tLoss: 0.477357, Images:25.08%\n",
      "\tLoss: 0.451750, Images:50.16%\n",
      "\tLoss: 0.423474, Images:75.24%\n",
      "Epoch:    24, loss: 71.07673817873001, acc: 0.852665\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "----------\n",
      "\tLoss: 0.317306, Images:0.00%\n",
      "\tLoss: 0.615339, Images:25.08%\n",
      "\tLoss: 0.193055, Images:50.16%\n",
      "\tLoss: 0.507581, Images:75.24%\n",
      "Epoch:    25, loss: 70.13671393692493, acc: 0.859718\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "----------\n",
      "\tLoss: 0.162736, Images:0.00%\n",
      "\tLoss: 0.642202, Images:25.08%\n",
      "\tLoss: 0.630091, Images:50.16%\n",
      "\tLoss: 0.297726, Images:75.24%\n",
      "Epoch:    26, loss: 68.34716738760471, acc: 0.859875\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "----------\n",
      "\tLoss: 0.225480, Images:0.00%\n",
      "\tLoss: 0.262861, Images:25.08%\n",
      "\tLoss: 0.428118, Images:50.16%\n",
      "\tLoss: 0.341154, Images:75.24%\n",
      "Epoch:    27, loss: 68.54070855677128, acc: 0.860345\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "----------\n",
      "\tLoss: 0.595565, Images:0.00%\n",
      "\tLoss: 0.479776, Images:25.08%\n",
      "\tLoss: 0.297267, Images:50.16%\n",
      "\tLoss: 0.434091, Images:75.24%\n",
      "Epoch:    28, loss: 67.28239782899618, acc: 0.865517\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "----------\n",
      "\tLoss: 0.340151, Images:0.00%\n",
      "\tLoss: 0.250940, Images:25.08%\n",
      "\tLoss: 0.297576, Images:50.16%\n",
      "\tLoss: 0.229701, Images:75.24%\n",
      "Epoch:    29, loss: 66.73375897854567, acc: 0.865674\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "----------\n",
      "\tLoss: 0.261717, Images:0.00%\n",
      "\tLoss: 0.623041, Images:25.08%\n",
      "\tLoss: 0.425607, Images:50.16%\n",
      "\tLoss: 0.307330, Images:75.24%\n",
      "Epoch:    30, loss: 65.34156595170498, acc: 0.871944\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "----------\n",
      "\tLoss: 0.260861, Images:0.00%\n",
      "\tLoss: 0.359934, Images:25.08%\n",
      "\tLoss: 0.451934, Images:50.16%\n",
      "\tLoss: 0.359105, Images:75.24%\n",
      "Epoch:    31, loss: 65.7936862707138, acc: 0.865517\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "----------\n",
      "\tLoss: 0.388881, Images:0.00%\n",
      "\tLoss: 0.582793, Images:25.08%\n",
      "\tLoss: 0.400607, Images:50.16%\n",
      "\tLoss: 0.152598, Images:75.24%\n",
      "Epoch:    32, loss: 65.99711161851883, acc: 0.867398\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "----------\n",
      "\tLoss: 0.383816, Images:0.00%\n",
      "\tLoss: 0.289769, Images:25.08%\n",
      "\tLoss: 0.355091, Images:50.16%\n",
      "\tLoss: 0.288801, Images:75.24%\n",
      "Epoch:    33, loss: 62.79489162564278, acc: 0.877273\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "----------\n",
      "\tLoss: 0.314003, Images:0.00%\n",
      "\tLoss: 0.223745, Images:25.08%\n",
      "\tLoss: 0.293485, Images:50.16%\n",
      "\tLoss: 0.454545, Images:75.24%\n",
      "Epoch:    34, loss: 63.331862568855286, acc: 0.876803\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "----------\n",
      "\tLoss: 0.318016, Images:0.00%\n",
      "\tLoss: 0.431795, Images:25.08%\n",
      "\tLoss: 0.228230, Images:50.16%\n",
      "\tLoss: 0.275485, Images:75.24%\n",
      "Epoch:    35, loss: 61.49493762105703, acc: 0.876176\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "----------\n",
      "\tLoss: 0.330657, Images:0.00%\n",
      "\tLoss: 0.364433, Images:25.08%\n",
      "\tLoss: 0.411193, Images:50.16%\n",
      "\tLoss: 0.275952, Images:75.24%\n",
      "Epoch:    36, loss: 60.55186349153519, acc: 0.874608\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "----------\n",
      "\tLoss: 0.399391, Images:0.00%\n",
      "\tLoss: 0.312259, Images:25.08%\n",
      "\tLoss: 0.126959, Images:50.16%\n",
      "\tLoss: 0.319375, Images:75.24%\n",
      "Epoch:    37, loss: 60.22139663994312, acc: 0.882132\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "----------\n",
      "\tLoss: 0.373145, Images:0.00%\n",
      "\tLoss: 0.363700, Images:25.08%\n",
      "\tLoss: 0.228571, Images:50.16%\n",
      "\tLoss: 0.466894, Images:75.24%\n",
      "Epoch:    38, loss: 59.23557950556278, acc: 0.883856\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "----------\n",
      "\tLoss: 0.218110, Images:0.00%\n",
      "\tLoss: 0.180567, Images:25.08%\n",
      "\tLoss: 0.232193, Images:50.16%\n",
      "\tLoss: 0.466167, Images:75.24%\n",
      "Epoch:    39, loss: 58.63859087228775, acc: 0.884483\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "----------\n",
      "\tLoss: 0.171133, Images:0.00%\n",
      "\tLoss: 0.166358, Images:25.08%\n",
      "\tLoss: 0.225744, Images:50.16%\n",
      "\tLoss: 0.252551, Images:75.24%\n",
      "Epoch:    40, loss: 58.705858051776886, acc: 0.885266\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "----------\n",
      "\tLoss: 0.403324, Images:0.00%\n",
      "\tLoss: 0.292751, Images:25.08%\n",
      "\tLoss: 0.150214, Images:50.16%\n",
      "\tLoss: 0.175750, Images:75.24%\n",
      "Epoch:    41, loss: 55.73738989979029, acc: 0.889028\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "----------\n",
      "\tLoss: 0.313750, Images:0.00%\n",
      "\tLoss: 0.345400, Images:25.08%\n",
      "\tLoss: 0.257108, Images:50.16%\n",
      "\tLoss: 0.184478, Images:75.24%\n",
      "Epoch:    42, loss: 56.30087185651064, acc: 0.889028\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "----------\n",
      "\tLoss: 0.300622, Images:0.00%\n",
      "\tLoss: 0.199735, Images:25.08%\n",
      "\tLoss: 0.202000, Images:50.16%\n",
      "\tLoss: 0.272293, Images:75.24%\n",
      "Epoch:    43, loss: 53.72969501465559, acc: 0.892633\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "----------\n",
      "\tLoss: 0.141201, Images:0.00%\n",
      "\tLoss: 0.424946, Images:25.08%\n",
      "\tLoss: 0.345652, Images:50.16%\n",
      "\tLoss: 0.233164, Images:75.24%\n",
      "Epoch:    44, loss: 53.84227525442839, acc: 0.894984\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "----------\n",
      "\tLoss: 0.272805, Images:0.00%\n",
      "\tLoss: 0.256788, Images:25.08%\n",
      "\tLoss: 0.232834, Images:50.16%\n",
      "\tLoss: 0.231072, Images:75.24%\n",
      "Epoch:    45, loss: 53.18440521508455, acc: 0.898903\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "----------\n",
      "\tLoss: 0.781240, Images:0.00%\n",
      "\tLoss: 0.136957, Images:25.08%\n",
      "\tLoss: 0.281414, Images:50.16%\n",
      "\tLoss: 0.230694, Images:75.24%\n",
      "Epoch:    46, loss: 51.787987768650055, acc: 0.900940\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "----------\n",
      "\tLoss: 0.464747, Images:0.00%\n",
      "\tLoss: 0.459521, Images:25.08%\n",
      "\tLoss: 0.164382, Images:50.16%\n",
      "\tLoss: 0.252926, Images:75.24%\n",
      "Epoch:    47, loss: 52.728390105068684, acc: 0.901567\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "----------\n",
      "\tLoss: 0.232376, Images:0.00%\n",
      "\tLoss: 0.340391, Images:25.08%\n",
      "\tLoss: 0.265804, Images:50.16%\n",
      "\tLoss: 0.363368, Images:75.24%\n",
      "Epoch:    48, loss: 51.25356934964657, acc: 0.900784\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "----------\n",
      "\tLoss: 0.545775, Images:0.00%\n",
      "\tLoss: 0.272483, Images:25.08%\n",
      "\tLoss: 0.218400, Images:50.16%\n",
      "\tLoss: 0.242908, Images:75.24%\n",
      "Epoch:    49, loss: 47.964734334498644, acc: 0.910815\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs = 50\n",
    "train_loss1 = []\n",
    "val_loss1 = []\n",
    "train_acc1 = []\n",
    "val_acc1 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    model.train(True)\n",
    "    loss_train = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    print(f\"\\n\\nEpoch: {epoch}\\n{'-'*10}\")\n",
    "    \n",
    "    for batch, (data, labels) in enumerate(train_dataloader):\n",
    "                \n",
    "        pred = model(data)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_fn(pred, labels)\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accuracy\n",
    "        train_acc += (torch.argmax(torch.softmax(pred, dim=1), dim=1) == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        if batch%50 == 0:\n",
    "            print(f\"\\tLoss: {loss.item():>6f}, Images:{100*((batch*BATCH_SIZE)/len(train_dataloader.dataset)):.2f}%\")\n",
    "    \n",
    "    train_acc /= len(train_dataloader.dataset)\n",
    "    print(f\"Epoch: {epoch:>5}, loss: {loss_train}, acc: {train_acc:>4f}\")\n",
    "    \n",
    "    train_loss1.append(loss_train)\n",
    "    train_acc1.append(train_acc)\n",
    "    # writer.add_scalar(\"Loss/train\", loss_train, epoch)\n",
    "    # writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # validation\n",
    "    with torch.inference_mode():\n",
    "        loss_val = 0\n",
    "        test_acc = 0\n",
    "        for data, labels in val_dataloader:\n",
    "            pred = model(data)\n",
    "            \n",
    "            loss = loss_fn(pred, labels)\n",
    "            loss_val += loss\n",
    "            \n",
    "            # accuracy\n",
    "            test_acc += (torch.argmax(torch.softmax(pred, dim=1), dim=1) == labels).sum().item()\n",
    "            \n",
    "        test_acc /= len(test_dataloader.dataset)\n",
    "        val_loss1.append(loss_val)\n",
    "        val_acc1.append(test_acc)\n",
    "        # writer.add_scalar(\"Loss/val\", loss_val, epoch)\n",
    "        # writer.add_scalar(\"Accuracy/val\", train_acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48e47e65-1e86-45db-8ee0-763a7ea38b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\n",
    "    \"train_acc\": train_acc1,\n",
    "    \"train_loss\": train_loss1,\n",
    "    \"val_acc\": val_acc1,\n",
    "    \"val_loss\": val_loss1\n",
    "}, open(\"results/CNN2.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "baec4270-40c0-43a3-94ed-533d22a9a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/plasticDetector.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "35e21b82-5152-4042-9749-db86ecea66a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_plastic': 0, 'plastic': 1}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59453fd-d78d-469c-a827-fdc4bd0fa59f",
   "metadata": {},
   "source": [
    "## Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6b0fbd-3f45-4328-8afb-8a33b6bb68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\"./dataset5/\", transform=Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea0cc4b-a5b1-4847-bbd0-f2dfe3b66b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9971"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b391d956-d80f-48d3-b0a3-88e5a3d7a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=.20)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a3ccbf7-ca39-4257-ad8e-718b0be24c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(dataset, train_idx)\n",
    "val_data = Subset(dataset, val_idx)\n",
    "test_data = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3bc448d-b986-4b47-8954-c44a122f4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_data, BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ab80b991-4a3f-4ff9-84bd-fff153e9b597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlasticClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlasticClassifier2, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 86, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(86, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(64*10*10, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.linear_layers(out)\n",
    "        return out\n",
    "    \n",
    "model2 = PlasticClassifier2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e251ddc-9b65-4b0e-8e0c-7c8151d997eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlasticClassifier3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlasticClassifier3, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 3),            \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(8*52*52, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.linear_layers(out)\n",
    "        return out\n",
    "    \n",
    "model3 = PlasticClassifier3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e02101aa-a4a4-42f7-bcb5-45a756db514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21632"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*52*52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a144ca6e-d857-4785-8eeb-eeaa95a33cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlasticClassifier4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlasticClassifier4, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, 3, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(8*6*6, 128),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.linear_layers(out)\n",
    "        return out\n",
    "    \n",
    "model4 = PlasticClassifier4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2a33521-5986-4bc8-99c7-3702fe121f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = Compose([\n",
    "    transforms.RandomAffine(\n",
    "        degrees=(10, 70)),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomApply([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomHorizontalFlip()],p=0.6),\n",
    "    transforms.Resize((64,64), antialias=None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2418128-61fc-47f5-b666-2c0394c0fa34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    data_transforms(i[0])\n",
    "    print(model3(i[0]).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "01d98de5-1603-4ae3-9da7-ff1949e2a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_plastic': 0, 'plastic': 1}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b26bdadb-a994-41f5-a9fd-346cd3897dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model3.parameters(),\n",
    "                           lr=0.1,)\n",
    "                           # weight_decay=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30dfdb6-d8f5-449f-9426-eb0ea413d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19b68c58-ae2a-4a75-a507-4a4895d65d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5859825038422828"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "046e7353-26e5-474c-b61b-9e879adf6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0\n",
      "----------\n",
      "\tLoss: 0.690196, Images:0.00%\n",
      "\tLoss: 0.695276, Images:25.08%\n",
      "\tLoss: 0.696796, Images:50.16%\n",
      "\tLoss: 0.699331, Images:75.24%\n",
      "Epoch:     0, loss: 138.60688894987106, acc: 0.512226\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "----------\n",
      "\tLoss: 0.690005, Images:0.00%\n",
      "\tLoss: 0.696243, Images:25.08%\n",
      "\tLoss: 0.691450, Images:50.16%\n",
      "\tLoss: 0.698618, Images:75.24%\n",
      "Epoch:     1, loss: 138.6279951930046, acc: 0.503292\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "----------\n",
      "\tLoss: 0.673465, Images:0.00%\n",
      "\tLoss: 0.721081, Images:25.08%\n",
      "\tLoss: 0.682617, Images:50.16%\n",
      "\tLoss: 0.483316, Images:75.24%\n",
      "Epoch:     2, loss: 135.37070295214653, acc: 0.581505\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "----------\n",
      "\tLoss: 0.890743, Images:0.00%\n",
      "\tLoss: 0.583149, Images:25.08%\n",
      "\tLoss: 0.674459, Images:50.16%\n",
      "\tLoss: 0.558115, Images:75.24%\n",
      "Epoch:     3, loss: 125.79009971022606, acc: 0.659404\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "----------\n",
      "\tLoss: 0.654522, Images:0.00%\n",
      "\tLoss: 0.697204, Images:25.08%\n",
      "\tLoss: 0.692977, Images:50.16%\n",
      "\tLoss: 0.698317, Images:75.24%\n",
      "Epoch:     4, loss: 136.2929750084877, acc: 0.526489\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "----------\n",
      "\tLoss: 0.695293, Images:0.00%\n",
      "\tLoss: 0.685429, Images:25.08%\n",
      "\tLoss: 0.696010, Images:50.16%\n",
      "\tLoss: 0.668913, Images:75.24%\n",
      "Epoch:     5, loss: 138.69888484477997, acc: 0.510188\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "----------\n",
      "\tLoss: 0.694093, Images:0.00%\n",
      "\tLoss: 0.696171, Images:25.08%\n",
      "\tLoss: 0.698487, Images:50.16%\n",
      "\tLoss: 0.686677, Images:75.24%\n",
      "Epoch:     6, loss: 138.76581352949142, acc: 0.505172\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "----------\n",
      "\tLoss: 0.707007, Images:0.00%\n",
      "\tLoss: 0.687301, Images:25.08%\n",
      "\tLoss: 0.689095, Images:50.16%\n",
      "\tLoss: 0.694634, Images:75.24%\n",
      "Epoch:     7, loss: 138.82653617858887, acc: 0.491536\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "----------\n",
      "\tLoss: 0.685047, Images:0.00%\n",
      "\tLoss: 0.689971, Images:25.08%\n",
      "\tLoss: 0.698235, Images:50.16%\n",
      "\tLoss: 0.693476, Images:75.24%\n",
      "Epoch:     8, loss: 138.7272121310234, acc: 0.501254\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "----------\n",
      "\tLoss: 0.664796, Images:0.00%\n",
      "\tLoss: 0.697760, Images:25.08%\n",
      "\tLoss: 0.693379, Images:50.16%\n",
      "\tLoss: 0.680486, Images:75.24%\n",
      "Epoch:     9, loss: 138.84999364614487, acc: 0.492320\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "----------\n",
      "\tLoss: 0.691265, Images:0.00%\n",
      "\tLoss: 0.689936, Images:25.08%\n",
      "\tLoss: 0.693545, Images:50.16%\n",
      "\tLoss: 0.691836, Images:75.24%\n",
      "Epoch:    10, loss: 138.73118788003922, acc: 0.495925\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "----------\n",
      "\tLoss: 0.694358, Images:0.00%\n",
      "\tLoss: 0.691300, Images:25.08%\n",
      "\tLoss: 0.693973, Images:50.16%\n",
      "\tLoss: 0.696272, Images:75.24%\n",
      "Epoch:    11, loss: 138.66483968496323, acc: 0.507053\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "----------\n",
      "\tLoss: 0.687676, Images:0.00%\n",
      "\tLoss: 0.699570, Images:25.08%\n",
      "\tLoss: 0.694845, Images:50.16%\n",
      "\tLoss: 0.695360, Images:75.24%\n",
      "Epoch:    12, loss: 138.7958196401596, acc: 0.490909\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "----------\n",
      "\tLoss: 0.696923, Images:0.00%\n",
      "\tLoss: 0.682214, Images:25.08%\n",
      "\tLoss: 0.692123, Images:50.16%\n",
      "\tLoss: 0.708853, Images:75.24%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs = 30\n",
    "model_t = model3\n",
    "train_acc2 = []\n",
    "train_loss2 = []\n",
    "val_acc2 = []\n",
    "val_loss2 = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    model_t.train(True)\n",
    "    loss_train = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    print(f\"\\n\\nEpoch: {epoch}\\n{'-'*10}\")\n",
    "    \n",
    "    for batch, (data, labels) in enumerate(train_dataloader):\n",
    "        \n",
    "        if random() > 0.7:\n",
    "            data = data_transforms(data)\n",
    "        \n",
    "        pred = model_t(data)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_fn(pred, labels)\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accuracy\n",
    "        train_acc += (torch.argmax(torch.softmax(pred, dim=1), dim=1) == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        if batch%50 == 0:\n",
    "            print(f\"\\tLoss: {loss.item():>6f}, Images:{100*((batch*BATCH_SIZE)/len(train_dataloader.dataset)):.2f}%\")\n",
    "    \n",
    "    train_acc /= len(train_dataloader.dataset)\n",
    "    print(f\"Epoch: {epoch:>5}, loss: {loss_train}, acc: {train_acc:>4f}\")\n",
    "    train_loss2.append(loss_train)\n",
    "    train_acc2.append(train_acc)\n",
    "    # writer.add_scalar(\"Loss/train\", loss_train, epoch)\n",
    "    # writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    \n",
    "    model_t.eval()\n",
    "    \n",
    "    # validation\n",
    "    with torch.inference_mode():\n",
    "        loss_val = 0\n",
    "        test_acc = 0\n",
    "        for data, labels in val_dataloader:\n",
    "            pred = model_t(data)\n",
    "            \n",
    "            loss = loss_fn(pred, labels)\n",
    "            loss_val += loss\n",
    "            \n",
    "            # accuracy\n",
    "            test_acc += (torch.argmax(torch.softmax(pred, dim=1), dim=1) == labels).sum().item()\n",
    "            \n",
    "        test_acc /= len(test_dataloader.dataset)\n",
    "        val_loss2.append(loss_val)\n",
    "        val_acc2.append(test_acc)\n",
    "        # writer.add_scalar(\"Loss/val\", loss_val, epoch)\n",
    "        # writer.add_scalar(\"Accuracy/val\", train_acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005ad92-a595-466f-997e-5d6d87bd7b2b",
   "metadata": {},
   "source": [
    "Model 4:\n",
    "- just bags and bottles vs everything else\n",
    "\n",
    "Model 5:\n",
    "- increased padding to 10px to capture waters as well, and dropout in conv layers\n",
    "\n",
    "Model 6:\n",
    "- deeper model3 trained on padded set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e50d5d71-070f-449f-94c7-eb4f4c65f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "96e207c6-0e10-4ac1-8e87-2e8023126f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3, \"models/plasticDetector7.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1881e73-3c26-4a89-a6a9-df910c07eb6f",
   "metadata": {},
   "source": [
    "https://medium.com/@Sanskriti.Singh/an-emphasis-on-the-minimization-of-false-negatives-false-positives-in-binary-classification-9c22f3f9f73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b898d8-3984-4e40-8ae0-61482f301073",
   "metadata": {},
   "source": [
    "# calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddeef59e-de90-4b7a-a4b5-e325604ba1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.5,  75. , 112.5, 150. , 112.5, 187.5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([3,2,3,4,3,5])\n",
    "a/a.sum() * 750"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
